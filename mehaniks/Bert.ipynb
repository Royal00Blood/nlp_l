{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель БЕРТА – НЛП (https://www.geeksforgeeks.org/explanation-of-bert-model-nlp/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT можно использовать для различных задач обработки естественного языка (NLP), таких как:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Задача классификации\n",
    "   \n",
    "- BERT можно использовать для задач классификации, таких как анализ тональности, цель которого — классифицировать текст по различным категориям (положительный/отрицательный/нейтральный). BERT можно использовать, добавив слой классификации поверх вывода Transformer для токена [CLS].\n",
    "- Токен [CLS] представляет собой обобщённую информацию из всей входной последовательности. Это обобщённое представление затем можно использовать в качестве входных данных для слоя классификации, чтобы делать прогнозы для конкретной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ответ на вопрос\n",
    "   \n",
    "- В задачах по поиску ответов на вопросы, где от модели требуется найти и отметить ответ в заданной текстовой последовательности, для этой цели можно обучить BERT.\n",
    "- BERT обучается отвечать на вопросы, изучая два дополнительных вектора, которые обозначают начало и конец ответа. Во время обучения модели предоставляются вопросы и соответствующие отрывки, и она учится предсказывать начало и конец ответа в отрывке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Распознавание именованных объектов (NER)\n",
    "   \n",
    "- BERT можно использовать для NER, где целью является выявление и классификация сущностей (например, людей, организаций, дат) в текстовой последовательности.\n",
    "- Модель NER на основе BERT обучается, принимая выходной вектор каждого токена из Transformer и передавая его на уровень классификации. Этот уровень предсказывает метку именованной сущности для каждого токена, указывая тип сущности, которую он представляет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для токенизации и кодирования текста с помощью BERT мы будем использовать библиотеку «transformer» в Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Мы загрузим предварительно обученный токенизатор BERT с учетом регистра, используя BertTokenizer.from_pretrained(«bert-base-cased»).\n",
    "- tokenizer.encode(текст) разбивает входной текст на токены и преобразует его в последовательность идентификаторов токенов.\n",
    "- print(«Идентификаторы токенов:», кодировка)выводит идентификаторы токенов, полученные после кодирования.\n",
    "- tokenizer.convert_ids_to_tokens(кодировка) преобразует идентификаторы токенов обратно в соответствующие им токены.\n",
    "- print(«Токены:», токены) выводит токены, полученные после преобразования идентификаторов токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan\\miniconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "c:\\Users\\Ivan\\miniconda3\\envs\\nlp\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ivan\\.cache\\huggingface\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [101, 24705, 1204, 17095, 1942, 1110, 170, 1846, 2235, 1872, 1118, 3353, 1592, 2240, 117, 1359, 1113, 1103, 15175, 1942, 113, 9066, 15306, 11689, 118, 3972, 13809, 23763, 114, 4220, 119, 102]\n",
      "Tokens: ['[CLS]', 'Cha', '##t', '##GP', '##T', 'is', 'a', 'language', 'model', 'developed', 'by', 'Open', '##A', '##I', ',', 'based', 'on', 'the', 'GP', '##T', '(', 'Gene', '##rative', 'Pre', '-', 'trained', 'Trans', '##former', ')', 'architecture', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Input text\n",
    "text = 'ChatGPT is a language model developed by OpenAI, based on the GPT (Generative Pre-trained Transformer) architecture. '\n",
    "\n",
    "# Tokenize and encode the text\n",
    "encoding = tokenizer.encode(text)\n",
    "\n",
    "# Print the token IDs\n",
    "print(\"Token IDs:\", encoding)\n",
    "\n",
    "# Convert token IDs back to tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoding)\n",
    "\n",
    "# Print the corresponding tokens\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
